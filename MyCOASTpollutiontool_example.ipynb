{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c2f1682",
   "metadata": {},
   "source": [
    "## Mycoast Pollution Risk Operational Model\n",
    "\n",
    "This document will show users of [MyCoastLCS](https://gitlab.ecosystem-modelling.pml.ac.uk/ricardo.torres/mycoast-ftle.git) how to setup a first example of the tool using lagrangian simulations performed with [Pylag](https://gitlab.ecosystem-modelling.pml.ac.uk/PyLag/PyLag) (both codes require an account to PML's gitlab server, please sign up [here](https://www.pml.ac.uk/Modelling_at_PML/Access_Code)). Click on Other in the Model Code choice and specify PyLag in the comment box. PyLag is not needed to use MyCoastLCS however some changes to the code might be required to use a different lagrangian particle simulator. \n",
    "\n",
    "This notebook will guide you through the steps to track particles from source point locations, and to calculate LCS fields from a pylag (or other lagrangian model) simulation that includes a gridded release of particles.\n",
    "\n",
    "Simulations can be backwards or forwards and for any number of ensembles and integration times. The direction and integration time will determine the interpretation of the results, whether this is following particle pathways in time, backtracking to identify likely source locations, or displaying attractors or repelling barriers to lagrangian transport.\n",
    "\n",
    "For more information refer to the [LCS tutorial ](https://shaddenlab.berkeley.edu/uploads/LCS-tutorial/) and the documentation for __MyCoastLCS__.\n",
    "\n",
    "This notebook runs with the code provided [here](https://drive.google.com/drive/folders/1qfMO5PpzsDURat8wsYaXvvvlSP20I3xy?usp=sharing), which should be decompressed in the ```$HOME``` directory ```~/MyCOASTpollutiontool_example``` with the following folder structure:\n",
    "\n",
    "\n",
    "  ```\n",
    "  .\n",
    "├── input\n",
    "│   ├── bathingareas_kmsq.csv\n",
    "│   ├── ftle_initialpositions.dat\n",
    "│   ├── ftle.json\n",
    "│   ├── grid_metrics.nc\n",
    "│   ├── pylag_fvcom.cfg\n",
    "│   ├── shapefiles\n",
    "│   │   ├── bovisand.cpg\n",
    "│   │   ├── bovisand.dbf\n",
    "│   │   ├── bovisand.prj\n",
    "│   │   ├── bovisand.shp\n",
    "│   │   ├── bovisand.shx\n",
    "│   │   ├── cawsand.cpg\n",
    "│   │   ├── cawsand.dbf\n",
    "│   │   ├── cawsand.prj\n",
    "│   │   ├── cawsand.shp\n",
    "│   │   ├── cawsand.shx\n",
    "│   │   ├── crownhill.cpg\n",
    "│   │   ├── crownhill.dbf\n",
    "│   │   ├── crownhill.prj\n",
    "│   │   ├── crownhill.shp\n",
    "│   │   ├── crownhill.shx\n",
    "│   │   ├── firestone.cpg\n",
    "│   │   ├── firestone.dbf\n",
    "│   │   ├── firestone.prj\n",
    "│   │   ├── firestone.shp\n",
    "│   │   ├── firestone.shx\n",
    "│   │   ├── tinside.cpg\n",
    "│   │   ├── tinside.dbf\n",
    "│   │   ├── tinside.prj\n",
    "│   │   ├── tinside.shp\n",
    "│   │   └── tinside.shx\n",
    "│   ├── tamar_v2_0001.nc\n",
    "│   ├── tamar_v2_obc.dat\n",
    "│   ├── triggerpoints\n",
    "│   │   ├── 2017triggers.csv\n",
    "│   │   ├── CSO_ENGLAND2019.csv\n",
    "│   │   ├── CSO_PLYMOUTHSOUND_TRIGGERPOINTS.csv\n",
    "│   │   ├── CSO_TAMAR_TRIGGERPOINTS.csv\n",
    "│   │   ├── CSOtriggerpoints.ipynb\n",
    "│   │   └── Rainfall\n",
    "│   │       ├── 2017\n",
    "│   │       │   ├── annualRF_2017.nc\n",
    "│   │       │   ├── fail.csv\n",
    "│   │       │   ├── fixed.csv\n",
    "│   │       │   └── missing.csv\n",
    "│   │       └── 2019\n",
    "│   │           ├── annualRF_2019.nc\n",
    "│   │           ├── fail.csv\n",
    "│   │           ├── fixed.csv\n",
    "│   │           └── missing.csv\n",
    "│   └── wrfout_001.nc\n",
    "├── MyCOASTpollutiontool_example.ipynb\n",
    "├── simulations\n",
    "└── tables\n",
    "    ├── bovisand.csv\n",
    "    ├── cawsand.csv\n",
    "    ├── firestone.csv\n",
    "    └── tinside.csv\n",
    "```\n",
    "\n",
    "\n",
    "running the script  will generate a new output folder: Exp01. You can change this in the simname varibale below. Example input files are provided [in this google drive](https://drive.google.com/drive/folders/1qfMO5PpzsDURat8wsYaXvvvlSP20I3xy?usp=sharing) , however FVCOM and WRF files for todays date can be downloaded from the following THREDDS servers:\n",
    "\n",
    "[FVCOM] (https://data.ecosystem-modelling.pml.ac.uk/thredds/catalog/mycoast-all-files/Model/TAMAR_ESTUARY_FORECAST_PHY_001/tamar_estuary_forecast_phy_001_hourly_t_s_u_v_ssh/today_forecast/catalog.html)\n",
    " \n",
    "\n",
    "[WRF] (https://data.ecosystem-modelling.pml.ac.uk/thredds/catalog/mycoast-all-files/Model/TAMAR_ESTUARY_FORECAST_WIND_001/tamar_estuary_coast_forecast_wind_001_hourly/today_forecast/catalog.html)\n",
    "\n",
    "\n",
    "This notebook guides the user in running PyLag and the MyCOASTLCS tool to generate predictions of bathing water quality. Bathing water quality predictions are based on a combination of dispersal trajectories of particles representing pollutants from point source locations (in this case Combined Sewage Overspill sites),and the formation of Lagrangian Coherent Structures, which may act as a barrier to particle transport.\n",
    "\n",
    "This example is run on an FVCOM grid, however [PyLags documentation](https://pylag.readthedocs.io/en/latest/) shows how to setup for running using models defined on an [Arawaka A grid](https://pylag.readthedocs.io/en/latest/examples/arakawa_a_forward_tracking.html).\n",
    "\n",
    "## Pre-requisites\n",
    "\n",
    "The example below assumes you are running inside a Linux environment. These instructions have only been tested in systems running Fedora 29 and 33.  \n",
    "\n",
    "## Installing the software\n",
    "\n",
    "Prior to running this example, Pylag and the MyCOAST tool must be installed in a conda environment on the users' machine. To do this follow the steps below:\n",
    "\n",
    "If not already installed, install [miniconda](https://conda.io/projects/conda/en/latest/user-guide/install/linux.html) to a location of your choosing. Then, activate Conda, ensure conda is up to data, and add the channels conda-forge, geo-down-under and JimClark. The channel geo-down-under is needed for one of PyLag’s dependencies. The channel JimClark is a temporary distribution channel for PyLag. For example:\n",
    "\n",
    "```bash\n",
    "$ source /opt/miniconda/miniconda3/bin/activate\n",
    "$ conda update conda\n",
    "$ conda config --append channels conda-forge\n",
    "$ conda config --append channels geo-down-under\n",
    "$ conda config --append channels JimClark\n",
    "```\n",
    "\n",
    "The above code assumes miniconda3 was installed into the directory ```/opt/miniconda```, once the appropriate write permissions have been set. The default behaviour is to install miniconda3 into your home directory. This is, of course, also fine.\n",
    "\n",
    "\n",
    "### Installing Pylag\n",
    "\n",
    "With miniconda3 installed and configured, create a new environment in which to install PyLag using the following commands:\n",
    "\n",
    "```bash\n",
    "$ conda create -n pylag python=3.8\n",
    "$ conda activate pylag\n",
    "```\n",
    "\n",
    "then install pylag\n",
    "\n",
    "```bash\n",
    "(pylag) $ conda install -n pylag -c JimClark pylag\n",
    "```\n",
    "\n",
    "To test that PyLag has been correctly installed, type:\n",
    "\n",
    "```bash\n",
    "(pylag) $ python -c \"import pylag\"\n",
    "```\n",
    "\n",
    "which should exit without error. When installing PyLag with conda, all the dependencies should have been resolved, and you should have PyFVCOM installed. \n",
    "\n",
    "\n",
    "\n",
    "Alternatively, Pylag can be installed from PML's repository using the following instructions: \n",
    "\n",
    "```bash\n",
    "$ conda install conda-build -n pylag\n",
    "$ git clone https://gitlab.ecosystem-modelling.pml.ac.uk/PyLag/PyLag.git\n",
    "$ cd Pylag\n",
    "$ git pull\n",
    "$ conda build . \n",
    "$ conda install -n pylag --use-local pylag\n",
    "$ pip install  . \n",
    "```\n",
    "\n",
    "To generate the documentation from the developer branch you need to download the example files from [here](https://drive.google.com/drive/folders/15UX7Y9JnuLpnPAz700mzmzd917nTClxR?usp=sharing). \n",
    "\n",
    "To finally generate the documentation ... \n",
    "\n",
    "```bash\n",
    "$ cd doc; make html\n",
    "```\n",
    "\n",
    "### Installing the MyCoast tool\n",
    "\n",
    "With SSH access setup, you can clone the MyCoastLCS repository using the following commands:\n",
    "\n",
    "```bash\n",
    "$ mkdir -p $HOME/mycoast_code/mycoastlcs && cd $HOME/code/git/FTLE\n",
    "$ git clone https://gitlab.ecosystem-modelling.pml.ac.uk/ricardo.torres/mycoast-ftle.git>\n",
    "```\n",
    "and then swap to branch \n",
    "\n",
    "```bash\n",
    "$ git checkout --track origin/T_direction_styling\n",
    "``` \n",
    "\n",
    "When working within conda and pylag environment activated type:\n",
    "\n",
    "```bash\n",
    "$ python -m pip install .\n",
    "```\n",
    "\n",
    "### Additional python packages required \n",
    "\n",
    "Other Python packages that do not come standard in a miniconda installation, pylag or MyCoastLCS but that are needed to run this example are:\n",
    "\n",
    "```bash\n",
    "$ conda install -c conda-forge jupyter jupyter-lab -n pylag\n",
    "$ conda install -c conda-forge cartopy -n pylag\n",
    "$ conda install dask -n pylag\n",
    "$ conda install holoviews -n pylag\n",
    "$ conda install natsort -n pylag\n",
    "$ conda install -c conda-forge matplotlib -n pylag\n",
    "$ conda install -c conda-forge cmocean -n pylag\n",
    "$ conda install pandas -n pylag\n",
    "```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91e9e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import date,datetime,timedelta\n",
    "import numpy as np\n",
    "from math import radians, cos, sin, asin, sqrt\n",
    "import netCDF4 as nc\n",
    "import datetime\n",
    "import os \n",
    "from os.path import expanduser\n",
    "\n",
    "###this example uses WRF and FVCOM files for 22nd May 2021\n",
    "\n",
    "#haversine equation function for calculating the nearest WRF grid cell for each CSO site\n",
    "def distance(lat1, lon1, lat2, lon2):  \n",
    "    p = 0.017453292519943295  #Pi/180\n",
    "    a = 0.5 - cos((lat2-lat1)*p)/2 + cos(lat1*p)*cos(lat2*p) * (1-cos((lon2-lon1)*p)) / 2\n",
    "    return 12742 * asin(sqrt(a)) #2*R*asin..\n",
    "\n",
    "#cores to run pylag on (if running parallel)\n",
    "cores = 4\n",
    "print('pylag simulation running on ',cores,' cores')\n",
    "\n",
    "#if the example directory is saved anywhere other than your hom dirctory,\n",
    "#give the path here\n",
    "home = expanduser(\"~\")\n",
    "mycoast = f'{home}/MyCOASTpollutiontool_example'\n",
    "os.chdir(mycoast)\n",
    "wd = os.getcwd()\n",
    "print('working directory: ',wd,'\\n')\n",
    "input_dir = f'{wd}/input'\n",
    "print('input directory: ',input_dir,'\\n')\n",
    "\n",
    "simname = 'Exp01'\n",
    "\n",
    "#create a new run directory in the simulations folder\n",
    "simulation_dir = f\"{wd}/simulations/{simname}\"\n",
    "print('simulation directory: ',simulation_dir,'\\n')\n",
    "\n",
    "try:\n",
    "    os.makedirs(simulation_dir)\n",
    "except FileExistsError:\n",
    "    pass\n",
    "\n",
    "#make the new directory writeable\n",
    "os.chmod(simulation_dir,0o755)\n",
    "#path to daily FVCOM file\n",
    "FVCOMfile = f'{input_dir}/tamar_v2_0001.nc'\n",
    "\n",
    "#path to bathing site shapefiles\n",
    "shp_dir = f'{input_dir}/shapefiles'\n",
    "\n",
    "#CSO triggerpoint file\n",
    "#a jupyter notebook to guide you through creating a trigger point csv from \n",
    "#daily rainfall over a year (WRF output) and CSO annnual overspill data\n",
    "# is available in ~/{example_folder}/input/triggerpoints/\n",
    "\n",
    "CSOfile=f'{input_dir}/triggerpoints/CSO_PLYMOUTHSOUND_TRIGGERPOINTS.csv'\n",
    "\n",
    "#get a copy of the default config\n",
    "default_cfg = f'{input_dir}/pylag_fvcom.cfg'\n",
    "\n",
    "#grid metrics\n",
    "grid_metrics_file_name = f'{input_dir}/grid_metrics.nc'\n",
    "\n",
    "#seedfile for ftle\n",
    "ftle_seedfile = '/data/proteus1/scratch/moja/MyCOAST/mycoast_code/operational_model/resources/ftle_initialpositions.dat'\n",
    "\n",
    "\n",
    "##the grid metrics file and ftle seed file have been provided in the example documentation\n",
    "#however if you want to make your own, set these to false\n",
    "gridmetrics = True\n",
    "ftleseeds = True \n",
    "#import bathing area size csv data\n",
    "bathingareas = f'{input_dir}/bathingareas_kmsq.csv'\n",
    "\n",
    "tables = f'{mycoast}/tables'\n",
    "\n",
    "#ftle json\n",
    "ftlejson =f'{input_dir}/ftle.json'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83becbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Getting daily rainfall data from WRF')\n",
    "\n",
    "#read in daily WRF output and calculate daily rainfall at each of the CSO sites\n",
    "##read in todays WRF data\n",
    "WRFpath = f'{input_dir}/wrfout_001.nc'\n",
    "print('WRF files read in from: ',WRFpath)\n",
    "\n",
    "#read in the grid from the annual WRF file\n",
    "WRFfile = nc.Dataset(WRFpath, 'r')\n",
    "#read in coordinates\n",
    "WRFlat = WRFfile.variables['XLAT'][:][0,:,:]\n",
    "WRFlon = WRFfile.variables['XLONG'][:][0,:,:]\n",
    "#store as columns\n",
    "listlon = np.reshape(WRFlon, ((WRFlon.shape[0]*WRFlon.shape[1]), 1))\n",
    "listlat = np.reshape(WRFlat, ((WRFlat.shape[0]*WRFlat.shape[1]), 1))\n",
    "listlon = np.ma.filled(listlon)\n",
    "listlat = np.ma.filled(listlat)\n",
    "\n",
    "#read in rainfall\n",
    "dailyrain =  WRFfile.variables['RAINNC'][:][:,:,:]\n",
    "\n",
    "#WRF has a hindcast and forecast and rain is accumulated from the first timestep. Therefore to get the daily rainfall we need to \n",
    "#subtract rainfall, at the 13th timestep (12:00 yesterday) from the 21st timestep (12:00) today\n",
    "\n",
    "dailyrain = dailyrain[21,:,:] - dailyrain[13,:,:]\n",
    "\n",
    "#read in the CSO file to a pandas dataframe\n",
    "df=pd.read_csv(CSOfile, sep=',',header=0)\n",
    "\n",
    "CSOlon = np.asarray(df['lon'])\n",
    "CSOlat = np.asarray(df['lat'])\n",
    "TP = np.asarray(df['TriggerPoint'])\n",
    "\n",
    "#read in the grid from the FVCOM file\n",
    "file = nc.Dataset(FVCOMfile, 'r')\n",
    "FVCOMlat = file.variables['latc'][:]\n",
    "FVCOMlon = file.variables['lonc'][:]\n",
    "\n",
    "\n",
    "#create empty arrays for CSO FVCOM points\n",
    "CSOFVCOMlon = np.zeros(len(df))\n",
    "CSOFVCOMlat = np.zeros(len(df))\n",
    "\n",
    "print('determine CSO overspill in Plymouth Sound catchment')\n",
    "#loop through the CSO sites\n",
    "for x in range(len(df)):\n",
    "        #search for the coordinates of the CSO site\n",
    "    dis = np.zeros(len(FVCOMlon))\n",
    "    qlat = CSOlat[x]\n",
    "    qlon = CSOlon[x]\n",
    "    \n",
    "    #find the index of the node (lat/lon) nearest to the CSO site\n",
    "    for xx in range(len(FVCOMlon)):\n",
    "        dis[xx] = distance(qlat, qlon, FVCOMlat[xx], FVCOMlon[xx])\n",
    "   \n",
    "    mindex = np.argmin(dis)\n",
    "    \n",
    "    for xx in range(len(FVCOMlon)):\n",
    "        if FVCOMlon[xx] == FVCOMlon[mindex] and FVCOMlat[xx] == FVCOMlat[mindex]:\n",
    "            CSOFVCOMlon[x] = FVCOMlon[xx]\n",
    "            CSOFVCOMlat[x] = FVCOMlat[xx]\n",
    "\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "\n",
    "WRFindex_lon = np.zeros(len(df))\n",
    "WRFindex_lat = np.zeros(len(df))\n",
    "spill_bool = np.zeros(len(df))\n",
    "\n",
    "#loop through the CSO sites\n",
    "for x in range(len(df)):\n",
    "        #search for the coordinates of the CSO site\n",
    "    dis = np.zeros(len(listlon))\n",
    "    qlat = CSOlat[x]\n",
    "    qlon = CSOlon[x]\n",
    "    for j in range(len(listlon)):\n",
    "        dis[j] = distance(qlat, qlon, listlat[j], listlon[j])\n",
    "    mindex = np.argmin(dis)\n",
    "\n",
    "    \n",
    "    for i in range(WRFlon.shape[0]):\n",
    "        for j in range(WRFlon.shape[1]):\n",
    "            if WRFlon[i,j] == listlon[mindex] and WRFlat[i,j] == listlat[mindex]:\n",
    "                WRFindex = [i,j]\n",
    "                WRFindex_lon[x] = i\n",
    "                WRFindex_lat[x] = j\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "\n",
    "    #get rain at site location\n",
    "    rain = dailyrain[WRFindex[0],WRFindex[1]]\n",
    "    \n",
    "    if rain >= TP[x]:\n",
    "        spill_bool[x] = 1\n",
    "    else:\n",
    "        spill_bool[x] = 0\n",
    "\n",
    "spill_bool = spill_bool.astype(bool)        \n",
    "\n",
    "print('CSO release: ',spill_bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed141ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Creating the seedile for CSO overspill')\n",
    "\n",
    "#create the seedfile\n",
    "\n",
    "from datetime import timedelta, date\n",
    "from pylag.processing.coordinate import lonlat_from_utm, utm_from_lonlat\n",
    "from pylag.processing.input import create_initial_positions_file_single_group, create_initial_positions_file_multi_group\n",
    "from pylag.processing.release_zone import create_release_zone\n",
    "\n",
    "#import spills info for weighted particle release and calculate weighted metric\n",
    "spills = np.asarray(df['Spills'])\n",
    "spilldur = np.asarray(df['Spill_Duration'])\n",
    "weight = spilldur/spills\n",
    "del(spills)\n",
    "del(spilldur)\n",
    "\n",
    "#set number of particles released from each ensemble prior to weighting\n",
    "nbasic = 100\n",
    "radius = 0  # Release zone radius in meter\n",
    "depth = 0.0  # Depth of particles\n",
    "print('unweighted number of  particles per ensemble: ',nbasic)\n",
    "\n",
    "numspillsites = np.sum(spill_bool)\n",
    "print('number of active CSO overspill sites in study domain: ',numspillsites)\n",
    "\n",
    " #create empty arrays for spill locations and site specific weights\n",
    "spill_lon = np.zeros(len(df))\n",
    "spill_lat = np.zeros(len(df))\n",
    "spill_weight = np.zeros(len(df))\n",
    "\n",
    "\n",
    "for x in range(len(df)):\n",
    "    if spill_bool[x] == True:\n",
    "        spill_lon[x] = CSOFVCOMlon[x]\n",
    "        spill_lat[x] = CSOFVCOMlat[x]\n",
    "        spill_weight[x] = weight[x]\n",
    "    else:\n",
    "        spill_lon[x] = np.nan\n",
    "        spill_lat[x] = np.nan\n",
    "        spill_weight[x] = np.nan\n",
    "\n",
    "#remove NaNs to give list of spill locations for date\n",
    "spill_lon = spill_lon[~np.isnan(spill_lon)]\n",
    "spill_lat = spill_lat[~np.isnan(spill_lat)]\n",
    "spill_weight = spill_weight[~np.isnan(spill_weight)]\n",
    "\n",
    "relsites = len(spill_lon)\n",
    "siteno = len(df)\n",
    "zpos = len(spill_lon)\n",
    "\n",
    "# Output filename\n",
    "seedfile = f\"{simulation_dir}/PylagCSOseed_{simname}.dat\"\n",
    "\n",
    "# The group ID of this particle set (CSO sites have the ID number 1)\n",
    "group_id = 1\n",
    "release_zones = []\n",
    "\n",
    "###### if no particles are released by any CSO site we will release some ransom extra particles just to keep things ticking over:\n",
    "is_empty = spill_lon.size == 0.\n",
    "if is_empty is True:\n",
    "    extra_lon = -4.15  #random location\n",
    "    extra_lat = 50.32  #in domain\n",
    "    extrap = 1\n",
    "    group_id = 0\n",
    "    extrax,extray,zone  = utm_from_lonlat(extra_lon,extra_lat) \n",
    "    release_zone = create_release_zone(group_id, radius,np.asarray([extrax[0],extray[0]]), int(extrap), depth,\n",
    "                                           random=True)\n",
    "    release_zones.append(release_zone)\n",
    "    create_initial_positions_file_multi_group(seedfile, release_zones)\n",
    "    \n",
    "    #for parallel runs, the number of particles needs to be divisible by the number of cores. Read in the initial positions file and check the number of particles.\n",
    "    # if this is not divisible by the number of cores create a new release zone with extra particles to make up the number. we will filter out these particles \n",
    "    #in post processing\n",
    "    \n",
    "    sf = pd.read_csv(seedfile, sep=\" \",header=0)\n",
    "    num_p = sf.shape[0]\n",
    "\n",
    "    if cores % num_p == 0 and cores <= num_p == True:\n",
    "        print('number of particles are divisble by nymber of cores')\n",
    "        tot_p = num_p\n",
    "        print(f'Total particles : {tot_p}')\n",
    "    else:\n",
    "        if cores > num_p:\n",
    "            print('fewer particles than cores - adding extra particles to initial positions file')\n",
    "            extrap = cores - num_p\n",
    "        else:\n",
    "            print('number of particles are not divisble by number of cores - adding extra particles to initial positions file')\n",
    "            extrap = (np.ceil(num_p/cores)*cores)-num_p\n",
    "        print('adding ',extrap,' particles')\n",
    "        tot_p = (num_p + extrap)\n",
    "        print(f'Total particles : {tot_p}')\n",
    "        group_id = 0\n",
    "\n",
    "        #random location in domain\n",
    "        extra_lon = -4.15\n",
    "        extra_lat = 50.32\n",
    "        extrax,extray,zone  = utm_from_lonlat(extra_lon,extra_lat) \n",
    "        release_zone = create_release_zone(group_id, radius,np.asarray([extrax[0],extray[0]]), int(extrap), depth,\n",
    "                                           random=True)\n",
    "        release_zones.append(release_zone)\n",
    "        create_initial_positions_file_multi_group(seedfile, release_zones)\n",
    "\n",
    "\n",
    "else:\n",
    "    #convert to utm\n",
    "    spillx, spilly, epsg_code = utm_from_lonlat(spill_lon, spill_lat)\n",
    "    n = len(spilly)\n",
    "    # does it matter if there are repeated nodes? probably not\n",
    "    for x in range(len(spill_lon)):\n",
    "        release_zone = create_release_zone(group_id, radius,np.asarray([spillx[x],spilly[x]]), int(nbasic*spill_weight[x]), depth,\n",
    "                                           random=True)\n",
    "        release_zones.append(release_zone)\n",
    "\n",
    "\n",
    "    # Write data to file\n",
    "    create_initial_positions_file_multi_group(seedfile, release_zones)\n",
    "    \n",
    "\n",
    "    #for parallel runs, the number of particles needs to be divisible by the number of cores. Read in the initial positions file and check the number of particles.\n",
    "    # if this is not divisible by the number of cores create a new release zone with extra particles to make up the number. we will filter out theseparticles in post processing\n",
    "    sf = pd.read_csv(seedfile, sep=\" \",header=0)\n",
    "    num_p = sf.shape[0]\n",
    "    print('number of CSO particles released per hour in simulation:',' ',num_p)\n",
    "\n",
    "    \n",
    "    if cores % num_p == 0 and cores <= num_p == True:\n",
    "        print('number of particles are divisble by nymber of cores')\n",
    "        tot_p = num_p\n",
    "        print(f'Total particles : {tot_p}')\n",
    "    else:\n",
    "        if cores > num_p:\n",
    "            print('fewer particles than cores - adding extra particles to initial positions file')\n",
    "            extrap = cores - num_p\n",
    "        else:\n",
    "            print('number of particles are not divisble by number of cores - adding extra particles to initial positions file')\n",
    "            extrap = (np.ceil(num_p/cores)*cores)-num_p\n",
    "        print('adding ',extrap,' particles')\n",
    "        tot_p = (num_p + extrap)\n",
    "        print(f'Total particles per simulation: {tot_p}')\n",
    "        ppd = tot_p*12\n",
    "        print(f'Total particles per day: {ppd}')\n",
    "        group_id = 0\n",
    "\n",
    "            #random location in domain\n",
    "        extra_lon = -4.15\n",
    "        extra_lat = 50.32\n",
    "        extrax,extray,zone  = utm_from_lonlat(extra_lon,extra_lat) \n",
    "        release_zone = create_release_zone(group_id, radius,np.asarray([extrax[0],extray[0]]), int(extrap), depth,\n",
    "                                       random=True)\n",
    "        release_zones.append(release_zone)\n",
    "        create_initial_positions_file_multi_group(seedfile, release_zones)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8ec07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up pylag\n",
    "\n",
    "################################\n",
    "#  create the grid metrics file  #\n",
    "##################################\n",
    "\n",
    "# a grid metrics file exists in the resources folder but this section can create a new one if needed\n",
    "\n",
    "if gridmetrics == False:\n",
    "    ###fvcom###\n",
    "    print('creating grid metrics file')\n",
    "    from pylag.grid_metrics import create_fvcom_grid_metrics_file\n",
    "    # The file listing the location of open boundary nodes\n",
    "    obc_file_name = f'{input_dir}/tamar_v2_obc.dat'\n",
    "\n",
    "    # The name of the output file\n",
    "    grid_metrics_file_name = f'{input_dir}/grid_metrics.nc'\n",
    "\n",
    "    # Generate the file\n",
    "    create_fvcom_grid_metrics_file(FVCOMfile, obc_file_name, grid_metrics_file_name)\n",
    "\n",
    "    # read mesh\n",
    "    varsinfvcom = ['bathy', 'x', 'y', 'lon', 'lat', 'triangles']\n",
    "    fvcom = dict.fromkeys(varsinfvcom)\n",
    "\n",
    "    # read mesh variables\n",
    "    with nc.Dataset(grid_metrics_file_name) as fvcomdata:\n",
    "        fvcom['bathy'] = fvcomdata.variables['h'][:]\n",
    "        fvcom['x'] = fvcomdata.variables['x'][:]\n",
    "        fvcom['y'] = fvcomdata.variables['y'][:]\n",
    "        fvcom['lon'] = fvcomdata.variables['longitude'][:]\n",
    "        fvcom['lat'] = fvcomdata.variables['latitude'][:]\n",
    "        fvcom['triangles'] = fvcomdata.variables['nv'][:].transpose()\n",
    "\n",
    "##########################\n",
    "#    write the config    #\n",
    "##########################\n",
    "\n",
    "import configparser\n",
    "cf = configparser.ConfigParser()\n",
    "cf.read(default_cfg)\n",
    "\n",
    "print('writing the config file for pylag CSO simulation')\n",
    "# set the directories and output file name \n",
    "cf.set('GENERAL', 'in_dir',simulation_dir)\n",
    "cf.set('GENERAL', 'out_dir',simulation_dir)\n",
    "cf.set('GENERAL', 'output_file',f'pylag_CSO_run_{simname}')\n",
    "\n",
    " # Set the time to start simulations \n",
    "Date = datetime.datetime(2021,6,21)\n",
    "Date = datetime.datetime.combine(Date, datetime.datetime.min.time())\n",
    "date_string = Date.strftime('%Y-%m-%d %H:%M:%S')\n",
    "delta = timedelta(hours = 24)\n",
    "Date = Date - delta\n",
    "date_string = Date.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "cf.set('SIMULATION', 'start_datetime',date_string)\n",
    "print('Start time: {}'.format(cf.get('SIMULATION', 'start_datetime')))\n",
    "\n",
    "#Set the time to end simulations if not using an ensemble approach\n",
    "# cf.set('SIMULATION', 'end_datetime','2013-01-06 22:00:00')\n",
    "#if using an ensemble approach, set this to blank\n",
    "cf.set('SIMULATION', 'end_datetime','')\n",
    "print('End time: {}'.format(cf.get('SIMULATION', 'end_datetime')))\n",
    "\n",
    "# Specify that this is a forward tracking experiment\n",
    "cf.set('SIMULATION', 'time_direction','forward')\n",
    "print('Time direction: {}'.format(cf.get('SIMULATION', 'time_direction')))\n",
    "\n",
    "#set the path to the initial positions file\n",
    "cf.set('SIMULATION','initial_positions_file', seedfile)\n",
    "print('Seedfile: {}'.format(cf.get('SIMULATION', 'initial_positions_file')))\n",
    "\n",
    "# We will do an ensemble run\n",
    "# for this test we will restrict the ensemble to 24 instances \n",
    "cf.set('SIMULATION', 'number_of_particle_releases','24')\n",
    "print('Number of particle releases: {}'.format(cf.get('SIMULATION', 'number_of_particle_releases')))\n",
    "\n",
    "# set duration of each ensemble release  \n",
    "cf.set('SIMULATION', 'duration_in_days','1')\n",
    "print('Duration of each release (hours): {}'.format(cf.getfloat('SIMULATION', 'duration_in_days')*24))\n",
    "\n",
    "#set the particle release interval\n",
    "cf.set('SIMULATION', 'particle_release_interval_in_hours','1')\n",
    "print('Particle release interval: {}'.format(cf.get('SIMULATION', 'particle_release_interval_in_hours')))\n",
    "\n",
    "# Use depth restoring, and restore particle depths to the ocean surface\n",
    "cf.set('SIMULATION', 'depth_restoring','True')\n",
    "print('Use depth restoring: {}'.format(cf.get('SIMULATION', 'depth_restoring')))\n",
    "print('Restore particles to a depth of: {} m'.format(cf.get('SIMULATION', 'fixed_depth')))\n",
    "\n",
    "# Specify that we are working with and unstructured FVCOM in cartesian coordinates\n",
    "cf.set('OCEAN_CIRCULATION_MODEL', 'name','FVCOM')\n",
    "cf.set('OCEAN_CIRCULATION_MODEL', 'coordinate_system','cartesian')\n",
    "print('Model name: {}'.format(cf.get('OCEAN_CIRCULATION_MODEL', 'name')))\n",
    "print('Coordinate system: {}'.format(cf.get('OCEAN_CIRCULATION_MODEL', 'coordinate_system')))\n",
    "\n",
    "# Set the location of the grid metrics and input files\n",
    "cf.set('OCEAN_CIRCULATION_MODEL', 'data_dir',input_dir)\n",
    "print('Data directory: {}'.format(cf.get('OCEAN_CIRCULATION_MODEL', 'data_dir')))\n",
    "\n",
    "cf.set('OCEAN_CIRCULATION_MODEL', 'grid_metrics_file', grid_metrics_file_name)\n",
    "print('Path to grid metrics file: {}'.format(cf.get('OCEAN_CIRCULATION_MODEL', 'grid_metrics_file')))\n",
    "\n",
    "# Set fvcom output file name stem\n",
    "# it is important that the non-stem files can be numerically ordered by wildcard \n",
    "cf.set('OCEAN_CIRCULATION_MODEL', 'data_file_stem', 'tamar_v2_0') \n",
    "print('File name stem of input files: {}'.format(cf.get('OCEAN_CIRCULATION_MODEL', 'data_file_stem')))\n",
    "\n",
    "cf.set('NUMERICS', 'iterative_method', 'AdvDiff_Milstein_3D') \n",
    "\n",
    "# Save a copy in the simulation directory\n",
    "with open(f\"{simulation_dir}/pylagcso{simname}.cfg\", 'w') as config:\n",
    "    cf.write(config)\n",
    "pcfg = f'{simulation_dir}/pylagcso{simname}.cfg'    \n",
    "\n",
    "###################\n",
    "#  setup the run  #\n",
    "###################\n",
    "\n",
    "import subprocess\n",
    "import sys\n",
    "import stat\n",
    "\n",
    "# Change to the run directory and launch\n",
    "os.chdir(simulation_dir)\n",
    "print(f'running pylag for CSO in {simulation_dir}')\n",
    "\n",
    "# write submit script \n",
    "with open(f\"csorun_{simname}.sh\", \"w\") as f:\n",
    "    f.write(\"#!//usr/bin/env bash\\n\")\n",
    "    f.write(\"set dir .\\n\")\n",
    " #  f.write(f\"python -m pylag.main -c {pcfg}\\n\") # for serial applications\n",
    "    f.write(f\"mpiexec -np {cores} python -m pylag.parallel.main -c {pcfg}\\n\") # for parallel applications\n",
    "    \n",
    "os.chmod(f\"csorun_{simname}.sh\", stat.S_IRWXU)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c065ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#run pylag\n",
    "\n",
    "try:\n",
    "    subprocess.call([f'./csorun_{simname}.sh'])\n",
    "except:\n",
    "    print('Run failed.')\n",
    "    pass\n",
    "print('pylag for CSO ran sucessfully')\n",
    "\n",
    "##you can follow the progress of the pylag run by typing tail -f pylag_out.log in the simulation directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987528cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### create plot of cso particles at midday\n",
    "print('plotting CSO particles at midday ')\n",
    "from pylag.processing.ncview import Viewer\n",
    "from datetime import timedelta\n",
    "\n",
    "datelist = []\n",
    "time_indexlist = []\n",
    "lonslist=[]\n",
    "latslist = []\n",
    "lonspaths_list = []\n",
    "latspaths_list = []\n",
    "pidlist= []\n",
    "\n",
    "\n",
    "tof = 25\n",
    "#extract particle positions on midday on the quary day. we will pull from each ensemble on midday of the query day\n",
    "for x in range(1,25):\n",
    "    tof = tof-1\n",
    "    \n",
    "    filename = f'{simulation_dir}/pylag_CSO_run_{simname}_{x}.nc'\n",
    "    print('ensemble ',simname,'_',x)\n",
    "    print('Time of flight: ',tof)\n",
    "    # Time of flight\n",
    "    time_of_flight = timedelta(hours=tof)\n",
    "\n",
    "    # Dataset holding particle positions\n",
    "    viewer = Viewer(filename, time_rounding=900)\n",
    "\n",
    "    # Get time index\n",
    "    date = viewer.date[0] + time_of_flight\n",
    "    datelist.append(date)\n",
    "    time_index = viewer.date.tolist().index(date)\n",
    "    time_indexlist.append(time_index)\n",
    "\n",
    "    # Convert positions into lons/lats\n",
    "    lons, lats = lonlat_from_utm(viewer('x')[time_index, :].squeeze(),\n",
    "                             viewer('y')[time_index, :].squeeze(), epsg_code='32630')\n",
    "    lonslist.append(lons)\n",
    "    latslist.append(lats)\n",
    "    \n",
    "    # Convert all pathline coordinates into lons/lats\n",
    "    x = viewer('x')[:time_index, :].squeeze()\n",
    "    y = viewer('y')[:time_index, :].squeeze()\n",
    "    arr_size = x.shape\n",
    "    lons_paths, lats_paths = lonlat_from_utm(x.flatten(), y.flatten(), epsg_code='32630')\n",
    "        \n",
    "    lonspaths_list.append(lons_paths.reshape(arr_size))\n",
    "    latspaths_list.append(lats_paths.reshape(arr_size))\n",
    "    \n",
    "    pid = viewer('group_id')[:]\n",
    "    pidlist.append(pid)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fded1512",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract CSO points (pid = 1)\n",
    "csolons = []\n",
    "csolats = []\n",
    "\n",
    "for i in range(len(lonslist)):\n",
    "    boolarr = pidlist[i] == 1\n",
    "    Lon = lonslist[i]\n",
    "    Lat = latslist[i]\n",
    "    csolons.append(Lon[boolarr])\n",
    "    csolats.append(Lat[boolarr])\n",
    "    \n",
    "import cartopy.crs as ccrs\n",
    "import warnings\n",
    "\n",
    "from pylag.processing.plot import FVCOMPlotter\n",
    "from pylag.processing.plot import create_figure, colourmap\n",
    "from matplotlib.lines import Line2D\n",
    "from netCDF4 import Dataset\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Read in the bathymetry\n",
    "ds = Dataset(grid_metrics_file_name, 'r')\n",
    "bathy = -ds.variables['h'][:]\n",
    "blanks = np.zeros_like(bathy)\n",
    "ds.close()\n",
    "del(ds)\n",
    "\n",
    "\n",
    "# Create figure - Plymouth Sound\n",
    "font_size = 15\n",
    "cmap = colourmap('h_r')\n",
    "\n",
    "\n",
    "fig, ax = create_figure(figure_size=(26., 26.), projection=ccrs.PlateCarree(), font_size=font_size, bg_color='gray')\n",
    "\n",
    "# Configure plotter\n",
    "plotter = FVCOMPlotter(grid_metrics_file_name,\n",
    "                       geographic_coords=True,\n",
    "                       font_size=font_size)\n",
    "\n",
    "xmin = -4.3\n",
    "xmax = -4.075\n",
    "ymin = 50.295\n",
    "ymax = 50.52\n",
    "\n",
    "\n",
    "plt_lims = np.array([xmin, xmax, ymin, ymax])\n",
    "extents = plt_lims\n",
    "\n",
    "# Plot the bathymetry again. We'll overlay pathlines on top of this.\n",
    "plotter.plot_field(ax, bathy, extents=extents, add_colour_bar=True, cb_label='Depth (m)',\n",
    "                   vmin=-60., vmax=0., cmap=cmap)\n",
    "\n",
    "\n",
    "for i in range(len(lonslist)):\n",
    "# Plot particle final positions\n",
    "    ax, scatter = plotter.scatter(ax, csolons[i], csolats[i], s=8, color='k', edgecolors='none')\n",
    "    \n",
    "# plot CSO sites\n",
    "for i in range(len(CSOlon)):\n",
    "    if spill_bool[i] == True:\n",
    "        ax, scatter = plotter.scatter(ax, CSOlon[i], CSOlat[i], s=70, color='r', edgecolors='k')\n",
    "    else:\n",
    "        ax, scatter = plotter.scatter(ax, CSOlon[i], CSOlat[i], s=50, marker = 'x', color='k')\n",
    "\n",
    "\n",
    "\n",
    "numpar = 0\n",
    "for i in range(len(csolons)):\n",
    "    numpar= numpar + len(csolons[i])\n",
    "\n",
    "plotter.set_title(ax, f'Target: 2021-05-22 12:00:00 n = {numpar}')\n",
    "\n",
    "import shapefile as shp  # Requires the pyshp package\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import fill\n",
    "\n",
    "\n",
    "sf = shp.Reader(f'{shp_dir}/cawsand.shp')\n",
    "for shape in sf.shapeRecords():\n",
    "    x = [i[0] for i in shape.shape.points[:]]\n",
    "    y = [i[1] for i in shape.shape.points[:]]\n",
    "    ax.fill(x,y,'purple',alpha=0.7)\n",
    "    \n",
    "sf = shp.Reader(f'{shp_dir}/bovisand.shp')\n",
    "for shape in sf.shapeRecords():\n",
    "    x = [i[0] for i in shape.shape.points[:]]\n",
    "    y = [i[1] for i in shape.shape.points[:]]\n",
    "    ax.fill(x,y,'yellow',alpha=0.7)\n",
    "\n",
    "sf = shp.Reader(f'{shp_dir}/firestone.shp')\n",
    "for shape in sf.shapeRecords():\n",
    "    x = [i[0] for i in shape.shape.points[:]]\n",
    "    y = [i[1] for i in shape.shape.points[:]]\n",
    "    ax.fill(x,y,'red',alpha=0.7)\n",
    "    \n",
    "    \n",
    "    \n",
    "sf = shp.Reader(f'{shp_dir}/tinside.shp')\n",
    "for shape in sf.shapeRecords():\n",
    "    x = [i[0] for i in shape.shape.points[:]]\n",
    "    y = [i[1] for i in shape.shape.points[:]]\n",
    "    ax.fill(x,y,'green',alpha=0.7)\n",
    "    \n",
    "legend_elements = [Line2D([0], [0], marker = 'o', color = 'w', markerfacecolor='yellow', markeredgecolor= 'yellow', markersize=7, label = 'Bovisand Bay'),\n",
    "                      Line2D([0], [0], marker = 'o', color = 'w', markerfacecolor='green', markeredgecolor= 'g', markersize=7, label = 'Tinside East'),\n",
    "                      Line2D([0], [0], marker = 'o', color = 'w', markerfacecolor='red', markeredgecolor= 'r', markersize=7, label = 'Firestone Bay'),\n",
    "                      Line2D([0], [0], marker = 'o', color = 'w', markerfacecolor='purple', markeredgecolor= 'purple', markersize=7, label = 'Kingsand Bay'),\n",
    "                      Line2D([0], [0], marker = 'o', color = 'w', markerfacecolor='red', markeredgecolor= 'black', markersize=15, label = 'Active CSOs'),\n",
    "                      Line2D([0], [0], marker = 'x', color = 'w', markerfacecolor='black', markeredgecolor= 'black', markersize=10, label = 'Inactive CSOs')]\n",
    "\n",
    "\n",
    "ax.legend(handles=legend_elements, loc='best',framealpha=1)\n",
    "\n",
    "plt.savefig(f'{simulation_dir}/Tamar_CSO_{simname}.png')\n",
    "plt.close()\n",
    "#zoom in on the sound\n",
    "xmin = -4.23\n",
    "xmax = -4.1\n",
    "ymin = 50.295\n",
    "ymax = 50.38\n",
    "\n",
    "fig, ax = create_figure(figure_size=(26., 26.), projection=ccrs.PlateCarree(), font_size=font_size, bg_color='gray')\n",
    "\n",
    "plt_lims = np.array([xmin, xmax, ymin, ymax])\n",
    "extents = plt_lims\n",
    "\n",
    "# Plot the bathymetry. We'll overlay particles on top of this.\n",
    "plotter.plot_field(ax, bathy, extents=extents, add_colour_bar=True, cb_label='Depth (m)',\n",
    "                   vmin=-60., vmax=0., cmap=cmap)\n",
    "\n",
    "\n",
    "for i in range(len(lonslist)):\n",
    "# Plot particle final positions\n",
    "    ax, scatter = plotter.scatter(ax, csolons[i], csolats[i], s=8, color='k', edgecolors='none')\n",
    "    \n",
    "# plot CSO sites\n",
    "for i in range(len(CSOlon)):\n",
    "    if spill_bool[i] == True:\n",
    "        ax, scatter = plotter.scatter(ax, CSOlon[i], CSOlat[i], s=70, color='r', edgecolors='k')\n",
    "    else:\n",
    "        ax, scatter = plotter.scatter(ax, CSOlon[i], CSOlat[i], s=50, marker = 'x', color='k')\n",
    "\n",
    "\n",
    "plotter.set_title(ax, f'Target: 2021-05-22 12:00:00 n = {numpar}')\n",
    "\n",
    "cawsand = shp.Reader(f'{shp_dir}/cawsand.shp')\n",
    "for shape in cawsand.shapeRecords():\n",
    "    x = [i[0] for i in shape.shape.points[:]]\n",
    "    y = [i[1] for i in shape.shape.points[:]]\n",
    "    ax.fill(x,y,'purple',alpha=0.7)\n",
    "    \n",
    "bovisand = shp.Reader(f'{shp_dir}/bovisand.shp')\n",
    "for shape in bovisand.shapeRecords():\n",
    "    x = [i[0] for i in shape.shape.points[:]]\n",
    "    y = [i[1] for i in shape.shape.points[:]]\n",
    "    ax.fill(x,y,'yellow',alpha=0.7)\n",
    "\n",
    "firestone = shp.Reader(f'{shp_dir}/firestone.shp')\n",
    "for shape in firestone.shapeRecords():\n",
    "    x = [i[0] for i in shape.shape.points[:]]\n",
    "    y = [i[1] for i in shape.shape.points[:]]\n",
    "    ax.fill(x,y,'red',alpha=0.7)\n",
    "       \n",
    "tinside = shp.Reader(f'{shp_dir}/tinside.shp')\n",
    "for shape in tinside.shapeRecords():\n",
    "    x = [i[0] for i in shape.shape.points[:]]\n",
    "    y = [i[1] for i in shape.shape.points[:]]\n",
    "    ax.fill(x,y,'green',alpha=0.7)\n",
    "    \n",
    "legend_elements = [Line2D([0], [0], marker = 'o', color = 'w', markerfacecolor='yellow', markeredgecolor= 'yellow', markersize=7, label = 'Bovisand Bay'),\n",
    "                      Line2D([0], [0], marker = 'o', color = 'w', markerfacecolor='green', markeredgecolor= 'g', markersize=7, label = 'Tinside East'),\n",
    "                      Line2D([0], [0], marker = 'o', color = 'w', markerfacecolor='red', markeredgecolor= 'r', markersize=7, label = 'Firestone Bay'),\n",
    "                      Line2D([0], [0], marker = 'o', color = 'w', markerfacecolor='purple', markeredgecolor= 'purple', markersize=7, label = 'Kingsand Bay'),\n",
    "                      Line2D([0], [0], marker = 'o', color = 'w', markerfacecolor='red', markeredgecolor= 'black', markersize=15, label = 'Active CSOs'),\n",
    "                      Line2D([0], [0], marker = 'x', color = 'w', markerfacecolor='black', markeredgecolor= 'black', markersize=10, label = 'Inactive CSOs')]\n",
    "\n",
    "\n",
    "ax.legend(handles=legend_elements, loc='best',framealpha=1)\n",
    "\n",
    "plt.savefig(f'{simulation_dir}/PlymouthSound_CSO_{simname}.png')\n",
    "#plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5127c4fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844acb73",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('counting CSO concentrations in Plymouth sound bathing areas')\n",
    "\n",
    "#count the number of CSO particles in each bathing area and calculate concentration of particles (per km2)\n",
    "from shapely.geometry import Point, Polygon\n",
    "from shapely.geometry import shape # shape() is a function to convert geo objects through the interface\n",
    "import csv\n",
    "#flatten particle location lists into single numpy arrays\n",
    "csolons = np.hstack(csolons)\n",
    "csolats = np.hstack(csolats)\n",
    "#csolons = np.concatenate(csolons).ravel()\n",
    "#csolats = np.concatenate(csolats).ravel()\n",
    "    \n",
    "bovisandcsocount = 0\n",
    "tinsidecsocount = 0\n",
    "firestonecsocount = 0\n",
    "cawsandcsocount = 0\n",
    "\n",
    "bovisandpoly = bovisand.shapes() \n",
    "tinsidepoly = tinside.shapes() \n",
    "firestonepoly = firestone.shapes() \n",
    "cawsandpoly = cawsand.shapes() \n",
    "\n",
    "for i in range(csolons.shape[0]):\n",
    "    point=Point(csolons[i],csolats[i])\n",
    "    if point.within(shape(bovisandpoly)): \n",
    "        bovisandcsocount = bovisandcsocount+1\n",
    "\n",
    "for i in range(csolons.shape[0]):\n",
    "    point=Point(csolons[i],csolats[i])\n",
    "    if point.within(shape(tinsidepoly)): \n",
    "        tinsidecsocount = tinsidecsocount+1\n",
    "        \n",
    "for i in range(csolons.shape[0]):\n",
    "    point=Point(csolons[i],csolats[i])\n",
    "    if point.within(shape(firestonepoly)): \n",
    "        firestonecsocount = firestonecsocount+1\n",
    "        \n",
    "for i in range(csolons.shape[0]):\n",
    "    point=Point(csolons[i],csolats[i])\n",
    "    if point.within(shape(cawsandpoly)): \n",
    "        cawsandcsocount = cawsandcsocount+1\n",
    "        \n",
    "\n",
    "with open(bathingareas) as csv_file:\n",
    "    bathing_df = csv.reader(csv_file, delimiter=',')\n",
    "    bathing_df = list(bathing_df)\n",
    "   \n",
    "bovikm = bathing_df[1]\n",
    "bovikm = bovikm[1]\n",
    "if bovisandcsocount == 0:\n",
    "    bovisandcsokm = 0\n",
    "else:\n",
    "    bovisandcsokm = float(bovisandcsocount)/float(bovikm)\n",
    "\n",
    "tinskm = bathing_df[2]\n",
    "tinskm = tinskm[1]\n",
    "if tinsidecsocount == 0:\n",
    "    tinsidecsokm = 0\n",
    "else:\n",
    "    tinsidecsokm = float(tinsidecsocount)/float(tinskm)\n",
    "\n",
    "firekm = bathing_df[3]\n",
    "firekm = firekm[1]\n",
    "if firestonecsocount == 0:\n",
    "    firestonecsokm = 0\n",
    "else:\n",
    "    firestonecsokm = float(firestonecsocount)/float(firekm)\n",
    "\n",
    "cawskm = bathing_df[4]\n",
    "cawskm = cawskm[1]\n",
    "if cawsandcsocount == 0:\n",
    "    cawsandcsokm = 0\n",
    "else:\n",
    "    cawsandcsokm = float(cawsandcsocount)/float(cawskm)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47f9217",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee1def2",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### FTLE and LCS\n",
    "#create the FTLE seedfile if we dont already have one\n",
    "if ftleseeds == False:\n",
    "    print('creating ftle seedfile for pylag')\n",
    "    #zoom in on the sound\n",
    "    # this will restrict the plot and distribution of the initial locations to the plymouth sound\n",
    "    plt_lims = np.array([xmin, xmax, ymin, ymax])\n",
    "\n",
    "    #create particle initial positions (evenly spaced throughout domain for FTLE run)\n",
    "\n",
    "    resolution = 250\n",
    "    x_grid = np.linspace(plt_lims[0], plt_lims[1], num=resolution)\n",
    "    y_grid = np.linspace(plt_lims[2], plt_lims[3], num=resolution)\n",
    "    x_grid_2d, y_grid_2d = np.meshgrid(x_grid, y_grid)\n",
    "    x_pts = x_grid_2d.flatten()\n",
    "    y_pts = y_grid_2d.flatten()\n",
    "    print(f'The initial positions for LCS calculations are spaced within the domain: with a resolution of {resolution} \\n ')\n",
    "    x_coords, y_coords, zone = utm_from_lonlat(x_pts, y_pts)\n",
    "    n = len(y_coords)\n",
    "    zpos = y_coords*0.0\n",
    "    \n",
    "    # The group ID of this particle set\n",
    "    group_id = '1'\n",
    "    \n",
    "    # Output filename\n",
    "    ftle_seedfile = f\"{input_dir}/ftle_initialpositions.dat\"\n",
    "\n",
    "    # Write data to file\n",
    "    create_initial_positions_file_single_group(ftle_seedfile, n, group_id, x_coords, y_coords, zpos)\n",
    "    print('seed file created')\n",
    "    print('number of particles: ',n)\n",
    "\n",
    "#edit the config\n",
    "ftlesimname = f\"PyLag_FTLE_{simname}\"\n",
    "cf.read(pcfg)\n",
    "\n",
    "cf.set('GENERAL', 'output_file',ftlesimname)\n",
    "\n",
    " # Set the time to start simulations \n",
    "Date = datetime.datetime(2021,6,21)\n",
    "Date = datetime.datetime.combine(Date, datetime.datetime.min.time())\n",
    "date_string = Date.strftime('%Y-%m-%d %H:%M:%S')\n",
    "delta = timedelta(hours = 0)\n",
    "Date = Date - delta\n",
    "date_string = Date.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "cf.set('SIMULATION', 'start_datetime',date_string)\n",
    "print('Start time: {}'.format(cf.get('SIMULATION', 'start_datetime')))\n",
    "\n",
    "# Specify that this is a reverse tracking experiment\n",
    "cf.set('SIMULATION', 'time_direction','reverse')\n",
    "print('Time direction: {}'.format(cf.get('SIMULATION', 'time_direction')))\n",
    "\n",
    "#set the path to the initial positions file\n",
    "cf.set('SIMULATION','initial_positions_file', ftle_seedfile)\n",
    "print('Seedfile: {}'.format(cf.get('SIMULATION', 'initial_positions_file')))\n",
    "# We will do an ensemble run\n",
    "\n",
    "# set duration of each ensemble release  \n",
    "cf.set('SIMULATION', 'duration_in_days','0.5')\n",
    "print('Duration of each release (hours): {}'.format(cf.getfloat('SIMULATION', 'duration_in_days')*24))\n",
    "\n",
    "cf.set('NUMERICS', 'iterative_method', 'Adv_RK4_3D')\n",
    "\n",
    "cf.set('OCEAN_CIRCULATION_MODEL','has_is_wet'  ,'True')\n",
    "cf.set('OCEAN_CIRCULATION_MODEL','horizontal_eddy_viscosity_constant' ,'10.0')\n",
    "cf.set('OCEAN_CIRCULATION_MODEL','time_dim_name'  ,'time')\n",
    "cf.set('OCEAN_CIRCULATION_MODEL','depth_dim_name'  ,'depth')\n",
    "cf.set('OCEAN_CIRCULATION_MODEL','latitude_dim_name'  ,'lat')\n",
    "cf.set('OCEAN_CIRCULATION_MODEL','longitude_dim_name'  ,'lon')\n",
    "cf.set('OCEAN_CIRCULATION_MODEL','time_var_name'  ,'time')\n",
    "cf.set('OCEAN_CIRCULATION_MODEL','uo_var_name'  ,'u')\n",
    "cf.set('OCEAN_CIRCULATION_MODEL','vo_var_name'  ,'v')\n",
    "cf.set('OCEAN_CIRCULATION_MODEL','wo_var_name'  ,'ww')\n",
    "cf.set('OCEAN_CIRCULATION_MODEL','zos_var_name'  ,'zeta')\n",
    "cf.set('OCEAN_CIRCULATION_MODEL','kh_var_name'  ,'')\n",
    "cf.set('OCEAN_CIRCULATION_MODEL','ah_var_name'  ,'')\n",
    "cf.set('OCEAN_CIRCULATION_MODEL','thetao_var_name'  ,'temp')\n",
    "cf.set('OCEAN_CIRCULATION_MODEL','so_var_name'  ,'salinity')\n",
    "\n",
    "# Save a copy in the simulation directory\n",
    "with open(f\"{simulation_dir}/pylag_ftle_{simname}.cfg\", 'w') as config:\n",
    "    cf.write(config)\n",
    "pcfg = f'{simulation_dir}/pylag_ftle_{simname}.cfg'    \n",
    "\n",
    "###################\n",
    "#  setup the run  #\n",
    "###################\n",
    "\n",
    "# Change to the run directory and launch\n",
    "os.chdir(simulation_dir)\n",
    "print(f'running pylag for ftle in {simulation_dir}')\n",
    "\n",
    "# write submit script \n",
    "with open(f\"ftlerun_{simname}.sh\", \"w\") as f:\n",
    "    f.write(\"#!//usr/bin/env bash\\n\")\n",
    "    f.write(\"set dir .\\n\")\n",
    " #  f.write(f\"python -m pylag.main -c {pcfg}\\n\") # for serial applications\n",
    "    f.write(f\"mpiexec -np {cores} python -m pylag.parallel.main -c {pcfg}\\n\") # for parallel applications\n",
    "    \n",
    "os.chmod(f\"ftlerun_{simname}.sh\", stat.S_IRWXU)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c53c93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#run pylag for ftle\n",
    "print('running pylag for FTLE/LCS')\n",
    "try:\n",
    "    subprocess.call([f'./ftlerun_{simname}.sh'])\n",
    "except:\n",
    "    print('Run failed.')\n",
    "    pass\n",
    "print('Pylag for FTLE/LCS ran sucessfully')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a97a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################\n",
    "# running MyCOAST_FTLE #\n",
    "########################\n",
    "\n",
    "\n",
    "fileroot = f'{simulation_dir}/PyLag_FTLE_{simname}'\n",
    "\n",
    "# write submit script \n",
    "with open(f\"{simulation_dir}/run-ftle{simname}.sh\", \"w\") as f:\n",
    "    f.write(\"#!//usr/bin/env bash\\n\")\n",
    "    f.write(\"set dir .\\n\")\n",
    "    f.write(\"echo '>>>> FTLE <<<<<'\\n\")\n",
    "    f.write(f\"python -m MYCOASTLCS -j {ftlejson} -i '{fileroot}*.nc' -o Pylag_.nc\\n\")\n",
    "\n",
    "    #make the script executable\n",
    "os.chmod(f\"{simulation_dir}/run-ftle{simname}.sh\", 0o755)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1990fe50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#run the mycoast tool\n",
    "print('running the mycoastlcs tool')\n",
    "try:\n",
    "    subprocess.call([f'./run-ftle{simname}.sh'])\n",
    "except:\n",
    "    print('Run failed.')\n",
    "    pass\n",
    "print('mycoastlcs tool ran sucessfully')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b920615d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from netCDF4 import Dataset\n",
    "# plots with ftle and lcs\n",
    "\n",
    "print('Plotting CSO and LCS fields at midday') \n",
    "from matplotlib import animation, rc\n",
    "import netCDF4\n",
    "from IPython.display import HTML\n",
    "\n",
    "ftlefile = f'{simulation_dir}/Pylag_ftle.nc'\n",
    "\n",
    "# Dataset holding FTLE/LCS fields\n",
    "with Dataset(ftlefile) as nc:\n",
    "    lon = nc.variables['x0'][:]\n",
    "    lat = nc.variables['y0'][:]\n",
    "    LCS = nc.variables['LCS_backward'][:, :, :]\n",
    "    FTLE = nc.variables['FTLE_backward'][:, :, :]\n",
    "    nctime = nc.variables['time']\n",
    "    numtime = nctime[:]\n",
    "    time = netCDF4.num2date(numtime, nctime.units)\n",
    "\n",
    "blanks = np.zeros_like(bathy)\n",
    "# apply mask to LCS fields as they are in the FTLE\n",
    "LCS_masked = np.ma.masked_array(LCS,mask=FTLE.mask)\n",
    "lon,lat = lonlat_from_utm(lon,lat,epsg_code='32630')\n",
    "LCSsum = np.sum(LCS_masked,axis = 0)\n",
    "LCSsum = LCSsum.astype('float')\n",
    "LCSsum[LCSsum == 0] = 'nan'\n",
    "\n",
    "colormap=plt.get_cmap('Greys_r')\n",
    "\n",
    "fig, ax = create_figure(figure_size=(26., 26.), projection=ccrs.PlateCarree(), font_size=font_size, bg_color='grey')\n",
    "\n",
    "empty = np.zeros_like(blanks)\n",
    "empty[:] = np.nan\n",
    "plotter.plot_field(ax, blanks, extents=plt_lims, add_colour_bar=False,cmap = colormap,vmin=-60,vmax=0,)\n",
    "colormap=plt.get_cmap('cool')\n",
    "plot = ax.pcolormesh(lon, lat, LCSsum[:,:],  cmap=colormap, transform=ccrs.PlateCarree(),animated=True,vmin=0,vmax=10)\n",
    "pos = ax.get_position().get_points()\n",
    "cax = fig.add_axes([pos[1,0]+0.01, pos[0,1], 0.02, pos[1,1] - pos[0,1]])\n",
    "cbar = fig.colorbar(plot, cax=cax)\n",
    "cbar.ax.tick_params(labelsize=font_size)\n",
    "cbar.set_label('LCS field', fontsize=font_size)\n",
    "\n",
    "\n",
    "# Plot particle final positions\n",
    "ax.scatter(csolons, csolats, s=12, color='k', edgecolors='none')\n",
    "\n",
    "# plot CSO sites\n",
    "for i in range(len(CSOlon)):\n",
    "    if spill_bool[i] == True:\n",
    "        ax.scatter(CSOlon[i], CSOlat[i], s=70, color='r', edgecolors='k')\n",
    "    else:\n",
    "        ax.scatter(CSOlon[i], CSOlat[i], s=50, marker = 'x', color='k')\n",
    "\n",
    "plotter.set_title(ax, f'Target: 2021-06-21 12:00:00  n = {numpar}')\n",
    "\n",
    "#plot = ax.pcolormesh(lon, lat, LCSsum[:,:],  cmap=colormap)\n",
    "cawsand = shp.Reader(f'{shp_dir}/cawsand.shp')\n",
    "for shape in cawsand.shapeRecords():\n",
    "    x = [i[0] for i in shape.shape.points[:]]\n",
    "    y = [i[1] for i in shape.shape.points[:]]\n",
    "    ax.plot(x,y,'purple')\n",
    "    \n",
    "bovisand = shp.Reader(f'{shp_dir}/bovisand.shp')\n",
    "for shape in bovisand.shapeRecords():\n",
    "    x = [i[0] for i in shape.shape.points[:]]\n",
    "    y = [i[1] for i in shape.shape.points[:]]\n",
    "    ax.plot(x,y,'yellow')\n",
    "\n",
    "firestone = shp.Reader(f'{shp_dir}/firestone.shp')\n",
    "for shape in firestone.shapeRecords():\n",
    "    x = [i[0] for i in shape.shape.points[:]]\n",
    "    y = [i[1] for i in shape.shape.points[:]]\n",
    "    ax.plot(x,y,'red')\n",
    "       \n",
    "tinside = shp.Reader(f'{shp_dir}/tinside.shp')\n",
    "for shape in tinside.shapeRecords():\n",
    "    x = [i[0] for i in shape.shape.points[:]]\n",
    "    y = [i[1] for i in shape.shape.points[:]]\n",
    "    ax.plot(x,y,'green')\n",
    "    \n",
    "legend_elements = [Line2D([0], [0], marker = 'o', color = 'w', markerfacecolor='yellow', markeredgecolor= 'yellow', markersize=7, label = 'Bovisand Bay'),\n",
    "                      Line2D([0], [0], marker = 'o', color = 'w', markerfacecolor='green', markeredgecolor= 'g', markersize=7, label = 'Tinside East'),\n",
    "                      Line2D([0], [0], marker = 'o', color = 'w', markerfacecolor='red', markeredgecolor= 'r', markersize=7, label = 'Firestone Bay'),\n",
    "                      Line2D([0], [0], marker = 'o', color = 'w', markerfacecolor='purple', markeredgecolor= 'purple', markersize=7, label = 'Kingsand Bay'),\n",
    "                      Line2D([0], [0], marker = 'o', color = 'w', markerfacecolor='red', markeredgecolor= 'black', markersize=15, label = 'Active CSOs'),\n",
    "                      Line2D([0], [0], marker = 'x', color = 'w', markerfacecolor='black', markeredgecolor= 'black', markersize=10, label = 'Inactive CSOs'),\n",
    "                      Line2D([0], [0], marker = '.', color = 'w', markerfacecolor='black', markeredgecolor= 'black', markersize=10, label = 'CSO particles')]\n",
    "\n",
    "\n",
    "ax.legend(handles=legend_elements, loc='best',framealpha=1)\n",
    "plt.savefig(f'{simulation_dir}/PlymouthSound_CSOLCS_{simname}.png')\n",
    "#plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652df88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print('Generating FTLE animations....')\n",
    "import cmocean.cm as cmo\n",
    "rc('animation', html='html5')\n",
    "blanks2 = blanks.data\n",
    "blanks2[:] = 0\n",
    "\n",
    "ftlemax = np.max(FTLE[:])\n",
    "ftlemin = np.min(FTLE[:])\n",
    "#### plotting the FTLE fields ###\n",
    "fig, ax = plt.subplots(1, 1, figsize=(20., 15.))\n",
    "font_size = 22\n",
    "#fig, ax = create_figure(figure_size=(26., 26.), font_size=font_size, bg_color='white')\n",
    "#plotter.plot_field(ax, blanks2, extents=plt_lims, add_colour_bar=False,vmin=0, vmax=1)\n",
    "#colormap=plt.get_cmap('binary')\n",
    "colormap = cmo.balance\n",
    "colormap = 'PuBu'\n",
    "fig.patch.set_facecolor('white')\n",
    "plt.rcParams.update({'font.size': 22})\n",
    "plot = ax.pcolormesh(lon, lat, FTLE[-1,:,:].squeeze(),  cmap=colormap,animated=True,vmin=ftlemin, vmax=ftlemax,shading='gouraud')\n",
    "ax.set_facecolor('grey')\n",
    "plt.xlabel('Longitude',fontsize=font_size)\n",
    "plt.ylabel('Latitude',fontsize=font_size)\n",
    "pos = ax.get_position().get_points()\n",
    "cax = fig.add_axes([pos[1,0]+0.01, pos[0,1], 0.02, pos[1,1] - pos[0,1]])\n",
    "cbar = fig.colorbar(plot, cax=cax)\n",
    "cbar.ax.tick_params(labelsize=font_size)\n",
    "cbar.set_label('FTLE field', fontsize=font_size)\n",
    "fig.suptitle(f'FTLE fields at midday')\n",
    "\n",
    "#gl = ax.gridlines(crs=ccrs.PlateCarree(), draw_labels=False, linewidth=1, color='gray', alpha=0.5, linestyle='-')\n",
    "#gl.top_labels = False\n",
    "#gl.right_labels = False\n",
    "#gl.xlines = False\n",
    "#gl.ylines = False\n",
    "plt.savefig(f'{simulation_dir}/ftle_surface.png')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bcc3189",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "###################################################\n",
    "# animating the time evolution of the FTLE fields #\n",
    "###################################################\n",
    "\n",
    "def init():\n",
    "#    plot.set_array([], mask=True)#\n",
    "    return (plot,)\n",
    "\n",
    "\n",
    "def animate(i):\n",
    "    data = FTLE[i,:,:].astype(float)\n",
    "    fig.suptitle('Target: %s ' % (time[i].strftime('%Y-%m-%d %H:%M')))\n",
    "    plot = ax.pcolormesh(lon, lat, data.squeeze(),  cmap=colormap,animated=True,vmin=ftlemin,vmax=ftlemax,shading='gouraud')\n",
    "    pos = ax.get_position().get_points()\n",
    "    cax = fig.add_axes([pos[1,0]+0.01, pos[0,1], 0.02, pos[1,1] - pos[0,1]])\n",
    "    cbar = fig.colorbar(plot, cax=cax)\n",
    "    cbar.ax.tick_params(labelsize=font_size)\n",
    "    cbar.set_label('FTLE field', fontsize=font_size)\n",
    "    return (plot,)\n",
    "\n",
    "# Prevent the basic figure from being plotted too\n",
    "plt.close(fig)\n",
    "\n",
    "anim = animation.FuncAnimation(fig, animate,  frames=len(FTLE[:,1,1]), interval=100, blit=True)\n",
    "anim.save(f'{simulation_dir}/FTLEAnimation.gif', writer='imagemagick', fps=5)\n",
    "\n",
    "HTML(anim.to_jshtml())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d5b083",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import ticker\n",
    "\n",
    "print('Generating LCS animations....')\n",
    "fig, ax = plt.subplots(1, 1, figsize=(20., 15.))\n",
    "\n",
    "colormap = 'Blues'\n",
    "fig.patch.set_facecolor('white')\n",
    "plt.rcParams.update({'font.size': 22})\n",
    "plot = ax.pcolormesh(lon, lat, LCS_masked[-1,:,:].squeeze(),  cmap=colormap,animated=True,shading='gouraud')\n",
    "ax.set_facecolor('grey')\n",
    "plt.xlabel('Longitude')\n",
    "plt.ylabel('Latitude')\n",
    "fig.suptitle(f'LCS fields at midday')\n",
    "plt.savefig(f'{simulation_dir}/lcs_surface.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9934a4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "###################################################\n",
    "# animating the time evolution of the LCS fields #\n",
    "###################################################\n",
    "\n",
    "def init():\n",
    "#    plot.set_array([], mask=True)#\n",
    "    return (plot,)\n",
    "\n",
    "\n",
    "def animate(i):\n",
    "    data = LCS_masked[i,:,:].astype(float)\n",
    "    fig.suptitle('Target: %s ' % (time[i].strftime('%Y-%m-%d %H:%M')))\n",
    "    plot = ax.pcolormesh(lon, lat, data.squeeze(),  cmap=colormap,animated=True,shading='gouraud')\n",
    "    return (plot,)\n",
    "\n",
    "# Prevent the basic figure from being plotted too\n",
    "plt.close(fig)\n",
    "\n",
    "anim = animation.FuncAnimation(fig, animate,  frames=len(LCS_masked[:,1,1]), interval=100, blit=True)\n",
    "anim.save(f'{simulation_dir}/LCSAnimation.gif', writer='imagemagick', fps=5)\n",
    "\n",
    "HTML(anim.to_jshtml())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910f6bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate the daily LCS at each site\n",
    "\n",
    "print('calculating LCS within Plymouth Sound bathing areas')\n",
    "from shapely.geometry import Point, Polygon\n",
    "from shapely.geometry import shape # shape() is a function to convert geo objects through the interface\n",
    "import csv\n",
    "\n",
    "LCSlons = []\n",
    "LCSlats = []\n",
    "\n",
    "for i in range(0,len(time)-1): #time\n",
    "    lats = []\n",
    "    lons = []\n",
    "    for j in range(0,len(lon)-1): #lon\n",
    "        for k in range(0,len(lat)-1): #lat\n",
    "            if LCS_masked[i,j,k] == 1:\n",
    "\n",
    "                lons.append(lon[j])\n",
    "                lats.append(lat[k])\n",
    "                \n",
    "            else:\n",
    "                continue\n",
    "\n",
    "    #time series lists of coordinates where LCS_masked == 1\n",
    "    LCSlons.append(lons)\n",
    "    LCSlats.append(lats)\n",
    "    \n",
    "\n",
    "bovisandpoly = bovisand.shapes() \n",
    "tinsidepoly = tinside.shapes() \n",
    "firestonepoly = firestone.shapes() \n",
    "cawsandpoly = cawsand.shapes() \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321a39ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c67e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "bovi_timeevo = []\n",
    "tins_timeevo = []\n",
    "caws_timeevo = []\n",
    "fire_timeevo = []\n",
    "\n",
    "for t in range(len(LCSlons)):\n",
    "    \n",
    "    tlonsarray = np.asarray(LCSlons[t])\n",
    "    tlatsarray = np.asarray(LCSlats[t])\n",
    "    \n",
    "    tbovi = 0\n",
    "    for i in range(len(tlonsarray)):\n",
    "        point=Point(tlonsarray[i],tlatsarray[i])\n",
    "        if point.within(shape(bovisandpoly)): \n",
    "            tbovi = tbovi+1\n",
    "            \n",
    "    ttins = 0\n",
    "    for i in range(len(tlonsarray)):\n",
    "        point=Point(tlonsarray[i],tlatsarray[i])\n",
    "        if point.within(shape(tinsidepoly)): \n",
    "            ttins = ttins+1\n",
    "            \n",
    "    tfire = 0\n",
    "    for i in range(len(tlonsarray)):\n",
    "        point=Point(tlonsarray[i],tlatsarray[i])\n",
    "        if point.within(shape(firestonepoly)): \n",
    "            tfire = tfire+1\n",
    "    \n",
    "    tcaws = 0\n",
    "    for i in range(len(tlonsarray)):\n",
    "        point=Point(tlonsarray[i],tlatsarray[i])\n",
    "        if point.within(shape(cawsandpoly)): \n",
    "            tcaws = tcaws+1\n",
    "            \n",
    "    bovi_timeevo.append(tbovi)\n",
    "    tins_timeevo.append(ttins)\n",
    "    fire_timeevo.append(tfire)\n",
    "    caws_timeevo.append(tcaws)\n",
    "\n",
    "bovi_timeevo = np.asarray(bovi_timeevo)\n",
    "tins_timeevo = np.asarray(tins_timeevo)\n",
    "fire_timeevo = np.asarray(fire_timeevo)\n",
    "caws_timeevo = np.asarray(caws_timeevo)\n",
    "\n",
    "bovisandlcscount = sum(bovi_timeevo)\n",
    "tinsidelcscount = sum(tins_timeevo)\n",
    "firestonelcscount = sum(fire_timeevo)\n",
    "cawsandlcscount = sum(caws_timeevo)\n",
    "\n",
    "\n",
    "bovisandlcskm = float(bovisandlcscount)/float(bovikm)\n",
    "tinsidelcskm = float(tinsidelcscount)/float(tinskm)\n",
    "firestonelcskm = float(firestonelcscount)/float(firekm)\n",
    "cawsandlcskm = float(cawsandlcscount)/float(cawskm)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19eac53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#plot the time evolution of the LCS fields at each bathing site \n",
    "\n",
    "maxy = np.maximum.reduce([bovi_timeevo,tins_timeevo,fire_timeevo,caws_timeevo])\n",
    "maxy = np.max(maxy)\n",
    "\n",
    "fig, axs = plt.subplots(4,sharex=True,figsize=(10,15),facecolor='white')\n",
    "fig.suptitle('2021-06-21',fontsize = 20)\n",
    "fig.tight_layout(rect=[0, 0.03, 1, 0.95]) \n",
    "\n",
    "# Set common labels\n",
    "fig.text(0.5, 0, 'Time Since Midnight', ha='center', va='center',fontsize = 20)\n",
    "fig.text(-0.05, 0.5, 'LCS concentration', ha='center', va='center',rotation='vertical',fontsize = 20)\n",
    "\n",
    "time_plt = list(range(1, 24))\n",
    "axs[0].plot(time_plt, fire_timeevo,'r')\n",
    "axs[1].plot(time_plt, tins_timeevo,'g')\n",
    "axs[2].plot(time_plt, caws_timeevo,'purple')\n",
    "axs[3].plot(time_plt, bovi_timeevo,'y')\n",
    "\n",
    "\n",
    "axs[0].set(ylim=(0,maxy),title='Firestone Bay')\n",
    "axs[1].set(ylim=(0,maxy),title='Tinside East')\n",
    "axs[2].set(ylim=(0,maxy),title='Cawsand Bay')\n",
    "axs[3].set(ylim=(0,maxy),title='Bovisand Bay')\n",
    "\n",
    "\n",
    "plt.xticks(np.arange(min(time_plt)+1, max(time_plt),2))\n",
    "plt.show()\n",
    "fig.savefig(f'{simulation_dir}/LCS_timeevo.png', facecolor=fig.get_facecolor(), transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b781f935",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save cso counts and LCS counts in csv\n",
    "today = '2021-06-21'\n",
    "print('saving CSO and LCS metrics to output table')\n",
    "boviT = f'{tables}/bovisand.csv'\n",
    "fields=[today,bovisandcsokm,bovisandlcskm]\n",
    "with open(boviT, 'a') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(fields)\n",
    "    \n",
    "fireT = f'{tables}/firestone.csv'\n",
    "fields=[today,firestonecsokm,firestonelcskm]\n",
    "with open(fireT, 'a') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(fields)\n",
    "    \n",
    "tinsT = f'{tables}/tinside.csv'\n",
    "fields=[today,tinsidecsokm,tinsidelcskm]\n",
    "with open(tinsT, 'a') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(fields)\n",
    "    \n",
    "cawsT = f'{tables}/cawsand.csv'\n",
    "fields=[today,cawsandcsokm,cawsandlcskm]\n",
    "with open(cawsT, 'a') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(fields)\n",
    "    \n",
    "print('Pollution risk tool completed for ',today)\n",
    "print('fin!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762eba3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
